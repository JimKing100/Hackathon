{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "nlp-1 (Python3)",
      "language": "python",
      "name": "nlp-1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "scrape.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh0CiJnRsBXI",
        "colab_type": "code",
        "outputId": "d0687e68-acba-4058-a843-96c5d21c21cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install squarify"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: squarify in /usr/local/lib/python3.6/dist-packages (0.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y133qOkzrDND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "import squarify\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import html as ihtml\n",
        "\n",
        "import requests\n",
        "import sqlite3\n",
        "\n",
        "count_df = pd.DataFrame(columns=['job_count', 'title_name', 'city_name'])\n",
        "global count_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCvFe_74rDNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_job_title(soup):\n",
        "    jobs = []\n",
        "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
        "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
        "            jobs.append(a[\"title\"])\n",
        "    return(jobs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfMKEEs5rDNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_company(soup):\n",
        "    companies = []\n",
        "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
        "        company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
        "        if len(company) > 0:\n",
        "            for b in company:\n",
        "                companies.append(b.text.strip())\n",
        "        else:\n",
        "            sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-linl-source\"})\n",
        "            for span in sec_try:\n",
        "                companies.append(span.text.strip())\n",
        "    return(companies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onup3OzurDNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_location(soup):\n",
        "    locations = []\n",
        "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
        "        try:\n",
        "            locations.append(div.find(name=\"span\", attrs={\"class\":\"location\"}).text)\n",
        "        except:\n",
        "            locations.append(\"None\")\n",
        "    return(locations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwxQyC4xrDN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_salary(soup):\n",
        "    salaries = []\n",
        "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
        "        try:\n",
        "            salaries.append(div.find(name=\"span\", attrs={\"class\":\"salaryText\"}).text.replace(\"\\n\",\"\"))\n",
        "        except:\n",
        "            salaries.append(\"None\")\n",
        "    return(salaries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG1FO5rgrDN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_job_title(soup):\n",
        "    jobs = []\n",
        "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
        "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
        "            jobs.append(a[\"title\"])\n",
        "    return(jobs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z49zqaYvrDOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_url(soup):\n",
        "    urls = []\n",
        "    for div1 in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
        "        for div2 in div1.find_all(name=\"div\", attrs={\"class\":\"title\"}):\n",
        "            for a in div2.find_all(name=\"a\", href=True):\n",
        "                urls.append(a['href'])\n",
        "    return(urls)\n",
        "\n",
        "def extract_desc(urls):\n",
        "    descs = []\n",
        "    for url in urls:\n",
        "        full_url = \"https://www.indeed.com\" + url\n",
        "        detail_page = requests.get(full_url)\n",
        "        detail_soup = BeautifulSoup(detail_page.text, \"html.parser\")\n",
        "        \n",
        "        for div in detail_soup.find_all(name=\"div\", attrs={\"id\":\"jobDescriptionText\"}):\n",
        "            descs.append(div.text)\n",
        "    return(descs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuIAkmwirDOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_count(soup):\n",
        "    for div in soup.find_all(name=\"div\", attrs={\"id\":\"searchCountPages\"}):\n",
        "        temp_str = div.text.replace(\" \", \"\")\n",
        "        temp_count_str = re.search('of(.*)jobs', temp_str)\n",
        "        count_str = re.sub('[^0-9]','', temp_count_str.group(1))\n",
        "        count = int(count_str)\n",
        "    return(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apMUcrzVrDOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_list(title_name, city_name, st_name):\n",
        "    max_results = 100\n",
        "    columns = [\"city\", \"job_title\", \"company\", \"location\", \"salary\", \"description\"]\n",
        "\n",
        "    city_url = \"https://www.indeed.com/jobs?q=\" + title_name + \\\n",
        "               \"&l=\" + city_name + \"%2C+\" + st_name\n",
        "    page = requests.get(city_url)\n",
        "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
        "    max_counter = extract_count(soup)\n",
        "    print(max_counter, title_name, city_name)\n",
        "    t_name = title_name.replace('+', ' ')\n",
        "    c_name = city_name.replace('+', ' ')\n",
        "    count_df.append({'job_count': max_counter,\n",
        "                                'title_name': t_name,\n",
        "                                'city_name': c_name}, ignore_index=True)\n",
        "\n",
        "    job_title_list = []\n",
        "    company_list = []\n",
        "    location_list = []\n",
        "    salary_list = []\n",
        "    desc_list = []\n",
        "\n",
        "    for start in range(0, max_results, 10):\n",
        "        city_url = \"https://www.indeed.com/jobs?q=\" + title_name + \\\n",
        "                   \"&l=\" + city_name + \"%2C+\" + st_name + \\\n",
        "                   \"&start=\" + str(start)\n",
        "        page = requests.get(city_url)\n",
        "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
        "\n",
        "        job_title_list.extend(extract_job_title(soup))\n",
        "        company_list.extend(extract_company(soup))\n",
        "        location_list.extend(extract_location(soup))\n",
        "        salary_list.extend(extract_salary(soup))\n",
        "        add_urls = extract_url(soup)\n",
        "        desc_list.extend(extract_desc(add_urls))\n",
        "\n",
        "    return job_title_list, company_list, location_list, salary_list, desc_list\n",
        "\n",
        "def job_db(title, city, st):   \n",
        "    j_list, c_list, l_list, s_list, d_list = extract_list(title, city, st)     \n",
        "    temp_df = pd.DataFrame(list(zip(j_list, c_list, l_list, s_list, d_list)), \n",
        "                          columns = ['job_title', 'company', 'location', 'salary', 'description'])\n",
        "    return temp_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btT5V6pSNCsj",
        "colab_type": "code",
        "outputId": "19df7161-247b-4557-acf2-7c0e96f00554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "temp1_df = job_db('data+scientist', 'San+Jose', 'CA')\n",
        "temp1_df['city'] = 'San Jose'\n",
        "temp2_df = job_db('data+scientist', 'San+Francisco', 'CA')\n",
        "temp2_df['city'] = 'San Francisco'\n",
        "temp3_df = job_db('data+scientist', 'Seattle', 'WA')\n",
        "temp3_df['city'] = 'Seattle'\n",
        "temp4_df = job_db('data+scientist', 'Washington', 'DC')\n",
        "temp4_df['city'] = 'Washington'\n",
        "temp5_df = job_db('data+scientist', 'New+York', 'NY')\n",
        "temp5_df['city'] = 'New York'\n",
        "temp6_df = job_db('data+scientist', 'Baltimore', 'MD')\n",
        "temp6_df['city'] = 'Baltimore'\n",
        "temp7_df = job_db('data+scientist', 'Boulder', 'CO')\n",
        "temp7_df['city'] = 'Boulder'\n",
        "temp8_df = job_db('data+scientist', 'San+Diego', 'CA')\n",
        "temp8_df['city'] = 'San Diego'\n",
        "temp9_df = job_db('data+scientist', 'Denver', 'CO')\n",
        "temp9_df['city'] = 'Denver'\n",
        "temp10_df = job_db('data+scientist', 'Huntsville', 'AL')\n",
        "temp10_df['city'] = 'Huntsville'\n",
        "temp11_df = job_db('data+scientist', 'Colorado+Springs', 'CO')\n",
        "temp11_df['city'] = 'Colorado Springs'\n",
        "temp12_df = job_db('data+scientist', 'Houston', 'TX')\n",
        "temp12_df['city'] = 'Houston'\n",
        "temp13_df = job_db('data+scientist', 'Trenton', 'NJ')\n",
        "temp13_df['city'] = 'Trenton'\n",
        "temp14_df = job_db('data+scientist', 'Dallas', 'TX')\n",
        "temp14_df['city'] = 'Dallas'\n",
        "temp15_df = job_db('data+scientist', 'Columbus', 'OH')\n",
        "temp15_df['city'] = 'Columbus'\n",
        "temp16_df = job_db('data+scientist', 'Austin', 'TX')\n",
        "temp16_df['city'] = 'Austin'\n",
        "temp17_df = job_db('data+scientist', 'Philadelphia', 'PA')\n",
        "temp17_df['city'] = 'Philadelphia'\n",
        "temp18_df = job_db('data+scientist', 'Durham', 'NC')\n",
        "temp18_df['city'] = 'Durham'\n",
        "temp19_df = job_db('data+scientist', 'Raleigh', 'NC')\n",
        "temp19_df['city'] = 'Raleigh'\n",
        "temp20_df = job_db('data+scientist', 'Atlanta', 'GA')\n",
        "temp20_df['city'] = 'Atlanta'\n",
        "\n",
        "data_scientist_df = pd.concat([temp1_df, temp2_df, temp3_df, temp4_df, temp5_df,\n",
        "                       temp6_df, temp7_df, temp8_df, temp9_df, temp10_df,\n",
        "                       temp11_df, temp12_df, temp13_df, temp14_df, temp15_df,\n",
        "                       temp16_df, temp17_df, temp18_df, temp19_df, temp20_df], ignore_index=True)\n",
        "\n",
        "print(data_scientist_df.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1315 data+scientist San+Jose\n",
            "937 data+scientist San+Francisco\n",
            "1106 data+scientist Seattle\n",
            "1180 data+scientist Washington\n",
            "980 data+scientist New+York\n",
            "165 data+scientist Baltimore\n",
            "161 data+scientist Boulder\n",
            "164 data+scientist San+Diego\n",
            "180 data+scientist Denver\n",
            "22 data+scientist Huntsville\n",
            "6 data+scientist Colorado+Springs\n",
            "100 data+scientist Houston\n",
            "91 data+scientist Trenton\n",
            "261 data+scientist Dallas\n",
            "74 data+scientist Columbus\n",
            "185 data+scientist Austin\n",
            "215 data+scientist Philadelphia\n",
            "146 data+scientist Durham\n",
            "148 data+scientist Raleigh\n",
            "257 data+scientist Atlanta\n",
            "(3350, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtJLD1unfnnG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "207e447b-1db8-4dd2-c0ce-90e4221e0c16"
      },
      "source": [
        "temp1_df = job_db('web+developer', 'San+Jose', 'CA')\n",
        "temp1_df['city'] = 'San Jose'\n",
        "temp2_df = job_db('web+developer', 'San+Francisco', 'CA')\n",
        "temp2_df['city'] = 'San Francisco'\n",
        "temp3_df = job_db('web+developer', 'Seattle', 'WA')\n",
        "temp3_df['city'] = 'Seattle'\n",
        "temp4_df = job_db('web+developer', 'Washington', 'DC')\n",
        "temp4_df['city'] = 'Washington'\n",
        "temp5_df = job_db('web+developer', 'New+York', 'NY')\n",
        "temp5_df['city'] = 'New York'\n",
        "temp6_df = job_db('web+developer', 'Baltimore', 'MD')\n",
        "temp6_df['city'] = 'Baltimore'\n",
        "temp7_df = job_db('web+developer', 'Boulder', 'CO')\n",
        "temp7_df['city'] = 'Boulder'\n",
        "temp8_df = job_db('web+developer', 'San+Diego', 'CA')\n",
        "temp8_df['city'] = 'San Diego'\n",
        "temp9_df = job_db('web+developer', 'Denver', 'CO')\n",
        "temp9_df['city'] = 'Denver'\n",
        "temp10_df = job_db('web+developer', 'Huntsville', 'AL')\n",
        "temp10_df['city'] = 'Huntsville'\n",
        "temp11_df = job_db('web+developer', 'Colorado+Springs', 'CO')\n",
        "temp11_df['city'] = 'Colorado Springs'\n",
        "temp12_df = job_db('web+developer', 'Houston', 'TX')\n",
        "temp12_df['city'] = 'Houston'\n",
        "temp13_df = job_db('web+developer', 'Trenton', 'NJ')\n",
        "temp13_df['city'] = 'Trenton'\n",
        "temp14_df = job_db('web+developer', 'Dallas', 'TX')\n",
        "temp14_df['city'] = 'Dallas'\n",
        "temp15_df = job_db('web+developer', 'Columbus', 'OH')\n",
        "temp15_df['city'] = 'Columbus'\n",
        "temp16_df = job_db('web+developer', 'Austin', 'TX')\n",
        "temp16_df['city'] = 'Austin'\n",
        "temp17_df = job_db('web+developer', 'Philadelphia', 'PA')\n",
        "temp17_df['city'] = 'Philadelphia'\n",
        "temp18_df = job_db('web+developer', 'Durham', 'NC')\n",
        "temp18_df['city'] = 'Durham'\n",
        "temp19_df = job_db('web+developer', 'Raleigh', 'NC')\n",
        "temp19_df['city'] = 'Raleigh'\n",
        "temp20_df = job_db('web+developer', 'Atlanta', 'GA')\n",
        "temp20_df['city'] = 'Atlanta'\n",
        "\n",
        "web_developer_df = pd.concat([temp1_df, temp2_df, temp3_df, temp4_df, temp5_df,\n",
        "                              temp6_df, temp7_df, temp8_df, temp9_df, temp10_df,\n",
        "                              temp11_df, temp12_df, temp13_df, temp14_df, temp15_df,\n",
        "                              temp16_df, temp17_df, temp18_df, temp19_df, temp20_df], ignore_index=True)\n",
        "print(web_developer_df.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1402 web+developer San+Jose\n",
            "1414 web+developer San+Francisco\n",
            "1422 web+developer Seattle\n",
            "3439 web+developer Washington\n",
            "1828 web+developer New+York\n",
            "881 web+developer Baltimore\n",
            "440 web+developer Boulder\n",
            "384 web+developer San+Diego\n",
            "597 web+developer Denver\n",
            "79 web+developer Huntsville\n",
            "68 web+developer Colorado+Springs\n",
            "368 web+developer Houston\n",
            "225 web+developer Trenton\n",
            "779 web+developer Dallas\n",
            "224 web+developer Columbus\n",
            "1039 web+developer Austin\n",
            "534 web+developer Philadelphia\n",
            "377 web+developer Durham\n",
            "360 web+developer Raleigh\n",
            "617 web+developer Atlanta\n",
            "(3631, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxjzVabzmpRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "7c6a536f-e751-4ae6-bf8e-7ccce347e54b"
      },
      "source": [
        "temp1_df = job_db('ux+designer', 'San+Jose', 'CA')\n",
        "temp1_df['city'] = 'San Jose'\n",
        "temp2_df = job_db('ux+designer', 'San+Francisco', 'CA')\n",
        "temp2_df['city'] = 'San Francisco'\n",
        "temp3_df = job_db('ux+designer', 'Seattle', 'WA')\n",
        "temp3_df['city'] = 'Seattle'\n",
        "temp4_df = job_db('ux+designer', 'Washington', 'DC')\n",
        "temp4_df['city'] = 'Washington'\n",
        "temp5_df = job_db('ux+designer', 'New+York', 'NY')\n",
        "temp5_df['city'] = 'New York'\n",
        "temp6_df = job_db('ux+designer', 'Baltimore', 'MD')\n",
        "temp6_df['city'] = 'Baltimore'\n",
        "temp7_df = job_db('ux+designer', 'Boulder', 'CO')\n",
        "temp7_df['city'] = 'Boulder'\n",
        "temp8_df = job_db('ux+designer', 'San+Diego', 'CA')\n",
        "temp8_df['city'] = 'San Diego'\n",
        "temp9_df = job_db('ux+designer', 'Denver', 'CO')\n",
        "temp9_df['city'] = 'Denver'\n",
        "temp10_df = job_db('ux+designer', 'Huntsville', 'AL')\n",
        "temp10_df['city'] = 'Huntsville'\n",
        "temp11_df = job_db('ux+designer', 'Colorado+Springs', 'CO')\n",
        "temp11_df['city'] = 'Colorado Springs'\n",
        "temp12_df = job_db('ux+designer', 'Houston', 'TX')\n",
        "temp12_df['city'] = 'Houston'\n",
        "temp13_df = job_db('ux+designer', 'Trenton', 'NJ')\n",
        "temp13_df['city'] = 'Trenton'\n",
        "temp14_df = job_db('ux+designer', 'Dallas', 'TX')\n",
        "temp14_df['city'] = 'Dallas'\n",
        "temp15_df = job_db('ux+designer', 'Columbus', 'OH')\n",
        "temp15_df['city'] = 'Columbus'\n",
        "temp16_df = job_db('ux+designer', 'Austin', 'TX')\n",
        "temp16_df['city'] = 'Austin'\n",
        "temp17_df = job_db('ux+designer', 'Philadelphia', 'PA')\n",
        "temp17_df['city'] = 'Philadelphia'\n",
        "temp18_df = job_db('ux+designer', 'Durham', 'NC')\n",
        "temp18_df['city'] = 'Durham'\n",
        "temp19_df = job_db('ux+designer', 'Raleigh', 'NC')\n",
        "temp19_df['city'] = 'Raleigh'\n",
        "temp20_df = job_db('ux+designer', 'Atlanta', 'GA')\n",
        "temp20_df['city'] = 'Atlanta'\n",
        "\n",
        "ux_designer_df = pd.concat([temp1_df, temp2_df, temp3_df, temp4_df, temp5_df,\n",
        "                            temp6_df, temp7_df, temp8_df, temp9_df, temp10_df,\n",
        "                            temp11_df, temp12_df, temp13_df, temp14_df, temp15_df,\n",
        "                            temp16_df, temp17_df, temp18_df, temp19_df, temp20_df], ignore_index=True)\n",
        "print(ux_designer_df.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "634 ux+designer San+Jose\n",
            "875 ux+designer San+Francisco\n",
            "952 ux+designer Seattle\n",
            "523 ux+designer Washington\n",
            "868 ux+designer New+York\n",
            "89 ux+designer Baltimore\n",
            "132 ux+designer Boulder\n",
            "107 ux+designer San+Diego\n",
            "147 ux+designer Denver\n",
            "8 ux+designer Huntsville\n",
            "6 ux+designer Colorado+Springs\n",
            "82 ux+designer Houston\n",
            "41 ux+designer Trenton\n",
            "178 ux+designer Dallas\n",
            "47 ux+designer Columbus\n",
            "274 ux+designer Austin\n",
            "145 ux+designer Philadelphia\n",
            "81 ux+designer Durham\n",
            "81 ux+designer Raleigh\n",
            "247 ux+designer Atlanta\n",
            "(2997, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIxfH9yfnheV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ca4a8b0c-2ad0-47a8-d681-e1788f5ef67d"
      },
      "source": [
        "temp1_df = job_db('ios+developer', 'San+Jose', 'CA')\n",
        "temp1_df['city'] = 'San Jose'\n",
        "temp2_df = job_db('ios+developer', 'San+Francisco', 'CA')\n",
        "temp2_df['city'] = 'San Francisco'\n",
        "temp3_df = job_db('ios+developer', 'Seattle', 'WA')\n",
        "temp3_df['city'] = 'Seattle'\n",
        "temp4_df = job_db('ios+developer', 'Washington', 'DC')\n",
        "temp4_df['city'] = 'Washington'\n",
        "temp5_df = job_db('ios+developer', 'New+York', 'NY')\n",
        "temp5_df['city'] = 'New York'\n",
        "temp6_df = job_db('ios+developer', 'Baltimore', 'MD')\n",
        "temp6_df['city'] = 'Baltimore'\n",
        "temp7_df = job_db('ios+developer', 'Boulder', 'CO')\n",
        "temp7_df['city'] = 'Boulder'\n",
        "temp8_df = job_db('ios+developer', 'San+Diego', 'CA')\n",
        "temp8_df['city'] = 'San Diego'\n",
        "temp9_df = job_db('ios+developer', 'Denver', 'CO')\n",
        "temp9_df['city'] = 'Denver'\n",
        "temp10_df = job_db('ios+developer', 'Huntsville', 'AL')\n",
        "temp10_df['city'] = 'Huntsville'\n",
        "temp11_df = job_db('ios+developer', 'Colorado+Springs', 'CO')\n",
        "temp11_df['city'] = 'Colorado Springs'\n",
        "temp12_df = job_db('ios+developer', 'Houston', 'TX')\n",
        "temp12_df['city'] = 'Houston'\n",
        "temp13_df = job_db('ios+developer', 'Trenton', 'NJ')\n",
        "temp13_df['city'] = 'Trenton'\n",
        "temp14_df = job_db('ios+developer', 'Dallas', 'TX')\n",
        "temp14_df['city'] = 'Dallas'\n",
        "temp15_df = job_db('ios+developer', 'Columbus', 'OH')\n",
        "temp15_df['city'] = 'Columbus'\n",
        "temp16_df = job_db('ios+developer', 'Austin', 'TX')\n",
        "temp16_df['city'] = 'Austin'\n",
        "temp17_df = job_db('ios+developer', 'Philadelphia', 'PA')\n",
        "temp17_df['city'] = 'Philadelphia'\n",
        "temp18_df = job_db('ios+developer', 'Durham', 'NC')\n",
        "temp18_df['city'] = 'Durham'\n",
        "temp19_df = job_db('ios+developer', 'Raleigh', 'NC')\n",
        "temp19_df['city'] = 'Raleigh'\n",
        "temp20_df = job_db('ios+developer', 'Atlanta', 'GA')\n",
        "temp20_df['city'] = 'Atlanta'\n",
        "\n",
        "ios_developer_df = pd.concat([temp1_df, temp2_df, temp3_df, temp4_df, temp5_df,\n",
        "                              temp6_df, temp7_df, temp8_df, temp9_df, temp10_df,\n",
        "                              temp11_df, temp12_df, temp13_df, temp14_df, temp15_df,\n",
        "                              temp16_df, temp17_df, temp18_df, temp19_df, temp20_df], ignore_index=True)\n",
        "print(ios_developer_df.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "759 ios+developer San+Jose\n",
            "465 ios+developer San+Francisco\n",
            "483 ios+developer Seattle\n",
            "351 ios+developer Washington\n",
            "317 ios+developer New+York\n",
            "83 ios+developer Baltimore\n",
            "107 ios+developer Boulder\n",
            "90 ios+developer San+Diego\n",
            "132 ios+developer Denver\n",
            "15 ios+developer Huntsville\n",
            "6 ios+developer Colorado+Springs\n",
            "52 ios+developer Houston\n",
            "24 ios+developer Trenton\n",
            "154 ios+developer Dallas\n",
            "28 ios+developer Columbus\n",
            "175 ios+developer Austin\n",
            "86 ios+developer Philadelphia\n",
            "48 ios+developer Durham\n",
            "47 ios+developer Raleigh\n",
            "134 ios+developer Atlanta\n",
            "(3224, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxO8nLwjrDOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_scientist_df['job'] = 'data scientist'\n",
        "web_developer_df['job'] = 'web developer'\n",
        "ux_designer_df['job'] = 'ux designer'\n",
        "ios_developer_df['job'] = 'ios developer'\n",
        "indeed_df = pd.concat([data_scientist_df, web_developer_df, ux_designer_df, ios_developer_df], ignore_index=True)\n",
        "indeed_df = indeed_df.drop_duplicates(keep=False) \n",
        "indeed_df = indeed_df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGR33_X2mDZp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "d3e08bc6-f869-4d3e-bb72-8702f73c40b8"
      },
      "source": [
        "indeed_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_title</th>\n",
              "      <th>company</th>\n",
              "      <th>location</th>\n",
              "      <th>salary</th>\n",
              "      <th>description</th>\n",
              "      <th>city</th>\n",
              "      <th>job</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Scientist (All Levels) - Santa Clara</td>\n",
              "      <td>LeanTaaS</td>\n",
              "      <td>Santa Clara, CA 95050</td>\n",
              "      <td>None</td>\n",
              "      <td>Help build technology that saves lives!\\n\\nWe'...</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Ford Motor Company</td>\n",
              "      <td>Palo Alto, CA</td>\n",
              "      <td>None</td>\n",
              "      <td>Data Scientist\\n\\n\\nJob description:\\n\\n\\nData...</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Siri - Embedded Data Scientist, Data organization</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Santa Clara Valley, CA 95014</td>\n",
              "      <td>None</td>\n",
              "      <td>Summary\\nPosted: Dec 16, 2019\\nRole Number:200...</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>California State University</td>\n",
              "      <td>San Jose, CA</td>\n",
              "      <td>None</td>\n",
              "      <td>The Data Scientist will leverage data that has...</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Spry Health</td>\n",
              "      <td>Palo Alto, CA</td>\n",
              "      <td>$100,000 - $135,000 a year</td>\n",
              "      <td>Spry Health’s mission is to build the world’s ...</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           job_title  ...             job\n",
              "0          Data Scientist (All Levels) - Santa Clara  ...  data scientist\n",
              "1                                     Data Scientist  ...  data scientist\n",
              "2  Siri - Embedded Data Scientist, Data organization  ...  data scientist\n",
              "3                                     Data Scientist  ...  data scientist\n",
              "4                                     Data Scientist  ...  data scientist\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQtq-mjCrDOW",
        "colab_type": "code",
        "outputId": "d649371e-b1e0-4caa-bfae-cbaf5be4b6de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "def convert_salary(sal_str, s_flag):\n",
        "    \n",
        "    sal_split = re.findall(r'\\d+', sal_str.replace(\",\", \"\"))\n",
        "    \n",
        "    if len(sal_split) == 2:\n",
        "        low_salary = int(sal_split[0])\n",
        "        high_salary = int(sal_split[1])\n",
        "    else:\n",
        "        low_salary = None\n",
        "        high_salary = None\n",
        "    \n",
        "    if s_flag == 'l':\n",
        "        salary = low_salary\n",
        "    else:\n",
        "        salary = high_salary\n",
        "    \n",
        "    return salary\n",
        "\n",
        "indeed_df['low_salary'] = indeed_df.apply(lambda x: convert_salary(x['salary'], 'l'), axis=1)\n",
        "indeed_df['high_salary'] = indeed_df.apply(lambda x: convert_salary(x['salary'], 'h'), axis=1)\n",
        "indeed_df = indeed_df.drop(columns=['salary'])\n",
        "\n",
        "indeed_df.head()                                      "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_title</th>\n",
              "      <th>company</th>\n",
              "      <th>location</th>\n",
              "      <th>description</th>\n",
              "      <th>city</th>\n",
              "      <th>job</th>\n",
              "      <th>low_salary</th>\n",
              "      <th>high_salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Scientist (All Levels) - Santa Clara</td>\n",
              "      <td>LeanTaaS</td>\n",
              "      <td>Santa Clara, CA 95050</td>\n",
              "      <td>Help build technology that saves lives!\\n\\nWe'...</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Ford Motor Company</td>\n",
              "      <td>Palo Alto, CA</td>\n",
              "      <td>Data Scientist\\n\\n\\nJob description:\\n\\n\\nData...</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Siri - Embedded Data Scientist, Data organization</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Santa Clara Valley, CA 95014</td>\n",
              "      <td>Summary\\nPosted: Dec 16, 2019\\nRole Number:200...</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>California State University</td>\n",
              "      <td>San Jose, CA</td>\n",
              "      <td>The Data Scientist will leverage data that has...</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Spry Health</td>\n",
              "      <td>Palo Alto, CA</td>\n",
              "      <td>Spry Health’s mission is to build the world’s ...</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>135000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           job_title  ... high_salary\n",
              "0          Data Scientist (All Levels) - Santa Clara  ...         NaN\n",
              "1                                     Data Scientist  ...         NaN\n",
              "2  Siri - Embedded Data Scientist, Data organization  ...         NaN\n",
              "3                                     Data Scientist  ...         NaN\n",
              "4                                     Data Scientist  ...    135000.0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ8FO9aaixTW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "2c46e012-544a-4d70-8ba7-838490857bf9"
      },
      "source": [
        "indeed_df.tail()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_title</th>\n",
              "      <th>company</th>\n",
              "      <th>location</th>\n",
              "      <th>description</th>\n",
              "      <th>city</th>\n",
              "      <th>job</th>\n",
              "      <th>low_salary</th>\n",
              "      <th>high_salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4945</th>\n",
              "      <td>Control Systems Programmer</td>\n",
              "      <td>Ford AV</td>\n",
              "      <td>Atlanta, GA</td>\n",
              "      <td>Compensation: Based Upon Experience, Benefits,...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>ios developer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4946</th>\n",
              "      <td>Software Engineer</td>\n",
              "      <td>ASSA ABLOY Opening Solutions</td>\n",
              "      <td>Marietta, GA</td>\n",
              "      <td>HID Global powers the trusted identities of th...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>ios developer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4947</th>\n",
              "      <td>Software Engineer</td>\n",
              "      <td>Assa Abloy</td>\n",
              "      <td>Marietta, GA</td>\n",
              "      <td>HID Global powers the trusted identities of th...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>ios developer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4948</th>\n",
              "      <td>Training Consultant</td>\n",
              "      <td>MicroStrategy</td>\n",
              "      <td>Atlanta, GA 30319</td>\n",
              "      <td>Job Description\\n\\nThe Role:\\nThe Training Con...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>ios developer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4949</th>\n",
              "      <td>Senior Software Engineer</td>\n",
              "      <td>Omada Health</td>\n",
              "      <td>Atlanta, GA</td>\n",
              "      <td>Omada Health is on a mission to inspire and en...</td>\n",
              "      <td>Atlanta</td>\n",
              "      <td>ios developer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       job_title  ... high_salary\n",
              "4945  Control Systems Programmer  ...         NaN\n",
              "4946           Software Engineer  ...         NaN\n",
              "4947           Software Engineer  ...         NaN\n",
              "4948         Training Consultant  ...         NaN\n",
              "4949    Senior Software Engineer  ...         NaN\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEcLUSONuZta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 48
        },
        "outputId": "4c234ec7-309f-41be-f633-0a0b77acce98"
      },
      "source": [
        "count_df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_count</th>\n",
              "      <th>title_name</th>\n",
              "      <th>city_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [job_count, title_name, city_name]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeG9aHa4rDOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.replace('\\\\n', ' ')               # remove newline\n",
        "    text = BeautifulSoup(text, \"lxml\").get_text() # remove html\n",
        "    text = text.replace('/', ' ')                 # remove forward slashes\n",
        "    text = re.sub(r'[^a-zA-Z ^0-9]', '', text)    # letters and numbers only\n",
        "    text = text.lower()                           # lower case\n",
        "    text = re.sub(r'(x.[0-9])', '', text)         # remove special characters\n",
        "    return text\n",
        "\n",
        "#indeed_df['description'] = indeed_df.apply(lambda x: clean_text(x['description']), axis=1)\n",
        "\n",
        "#indeed_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m41bi-PFrDOj",
        "colab_type": "code",
        "outputId": "5c70d5fa-0b9e-4b5c-837f-45759a75fee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "indeed_df['description'][0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Help build technology that saves lives!\\n\\nWe're a fast growing healthcare tech company that uses data science and machine learning to make our hospitals more efficient.\\n\\n\\nMore than 65 hospital systems including some of the nation's largest rely on our products to improve patient access and lower wait times.\\nWe've raised $70+ million dollars from prominent investors in healthcare.\\nOur team includes veteran executives and the brightest minds from Google, McKinsey, Stanford, MIT, Duke, Berkeley, UIUC, and more.\\nCBInsights recently named us among the top 100 AI companies in the world.\\n\\nWe're looking for extraordinary data scientists for our Santa Clara, California office. The Data Scientist role involves working on all stages of the data science pipeline, from acquiring and munging data, selecting appropriate models and algorithms and/or deriving custom algorithms, to testing and evaluating these algorithms and models and incorporating them into commercial products. She/He will work with a team of Data Scientists to create bleeding edge analytic technology. This is a chance to get in early with a rapidly growing Silicon Valley company and to participate in developing the next generation of truly game-changing, healthcare-related products. This is a mid/senior level position assuming 1-3+ years of prior experience.\\n\\nKey Responsibilities\\n\\nAnalyze various data sets and build sophisticated mathematical/statistical models\\nDesign and optimize algorithms to achieve the best solutions\\nWork with data analysts, software engineers, and product managers to contribute on building and implementing models.\\n\\nBasic Qualifications\\n\\nStrong quantitative and analytical skills with an advanced degree in a STEM discipline\\nExperience using Python and SQL\\nGreat understanding of optimization and machine learning algorithms\\nStrong problem-solving skills from data exploration > hypothesis development > hypothesis testing > production-ready models\\nAbility to communicate complex quantitative analysis in a clear, precise, and actionable manner\\nAbility to work collaboratively and independently\\n\\nPreferred Qualifications\\n\\nA Ph.D. degree in a STEM discipline\\nKnowledge of operational research\\nKnowledge of healthcare\\n\\nPersonal Characteristics\\n\\nA person with:\\n\\nA passion for data science and problem-solving in general\\nThe skill and motivation to take a high-level idea and see it through to completion with minimal supervision\\nThe desire and ability to work in a fast-paced, start-up atmosphere\\nA pragmatic approach to problem-solving, combined with the ability to thrive under the pressure of constant change and moving objectives\\nThe ability to work under tight deadlines and display grace under pressure\\nExcellent organizational, interpersonal, and communication skills (both written and verbal)\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFQOeIHCrDOm",
        "colab_type": "code",
        "outputId": "6a340ed5-b573-4da2-cb99-86008582a528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "indeed_df['description'][4]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Spry Health’s mission is to build the world’s largest physiological dataset to map human health, understand disease, and create new medical knowledge. We are innovating in the field of physiological signal processing and are looking for an experienced and motivated researcher to join our talented R&D team. The Research Engineer will take big responsibilities on our core science team and break new ground in health monitoring technology through physiological signal processing. We are the first to collect continuous physiological signals from thousands of patients.\\n\\nThis is an opportunity to step into a highly innovative healthcare startup and make real-world impact. Our dataset contains important information that would be a building block in medicine and physiological monitoring, discovering new physiological biomarkers that will help us combat disease. Working with physiological signals from users who are going about their daily life is very challenging—we have made significant progress but are looking for someone who will take our team to the next level. You’ll get the opportunity to design and execute experiments with medical grade reference devices both in-house and with high profile clinical partners around the country and internationally. As a Spry Algorithm Engineer you will get exposed to all aspects of the business and have a chance to leverage the benefits of a small, cohesive, cross-functional team.\\n\\nThis role is for you if you’re an independent individual eager to share your expertise as well as learn from our small team of world-class experts and engineers. You’re ready to dive into the enormous set of physiological data we’ve collected and lead your own projects combining signal processing, statistical modeling, and data analysis. You’re excited to face engineering challenges that have yet to be solved. Together we will invent brand-new technologies that will make a difference in peoples’ lives.\\nAs a member of the Algorithms Team, you will...\\nDevelop algorithms to extract vitals from physiological signals\\nSolve estimation and filtering problems to remove artifacts from motion and other sources of interference\\nStatistically model and analyze hardware, signal chain, and algorithm performance\\nCreate new sensor architectures\\nLearn about physiology, medicine, and new technical concepts through regular seminars with the rest of the team\\nQualifications and Requirements\\nPhD or Master’s with research experience in Engineering, Physics, Applied Physics, Math, Statistics, Computer Science, or related fields\\nExperience working with low SNR signals, and parameter extraction in the presence of noise\\nStrong foundation in math and statistics\\nProficient in Python and source control (Git)\\nInterest in physiology or biology\\nAbility to work independently with minimal input on broad project goals\\nEager to learn and excited to tackle unfamiliar engineering challenges with rigorous, analytical approaches\\nStrong critical thinker, active listener, and great communicator\\nCapacity to take work seriously while not taking oneself seriously—sense of humor is compulsory\\nSpry Health is transforming medical practices by providing remote care solutions for patients with chronic illness. Our FDA-cleared wearable device is the first to deliver predictive insights to healthcare organizations through continuous vital sign monitoring.\\n\\nSpry’s lean team is comprised of some of the brightest minds in Silicon Valley. We are committed to empowering patients by preventing hospital admissions and reducing medical spending, making our workplace a great fit for those ready to take ownership of challenging and meaningful work.\\n\\nAmbition to fundamentally change how people interact with healthcare is a prerequisite for your success at Spry. If you are collaborative, humble, resourceful, passionate about healthcare innovation, and looking for opportunities to grow and succeed, we want to hear from you. Bonus points if you enjoy puns, good coffee, and cooking challenges (because we do).\\n\\nSpry Health is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.\\n\\nAnnual Salary Range: $100,000 - $135,000\\nEquity Range: 0.10 - 0.25%\\nThis is a full-time position in Palo Alto, CA.\\nRemote work is not an option at this time.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejMqC3iJrDOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to sqlite3\n",
        "conn = sqlite3.connect('techsearch.sqlite3')\n",
        "curs = conn.cursor()\n",
        "curs.execute('drop table if exists listings')\n",
        "curs.execute('drop table if exists counts')\n",
        "indeed_df.to_sql('listings', con=conn)\n",
        "count_df.to_sql('counts', con=conn)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}