{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y133qOkzrDND"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import squarify\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import html as ihtml\n",
    "\n",
    "import requests\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCvFe_74rDNa"
   },
   "outputs": [],
   "source": [
    "def extract_job_title(soup):\n",
    "    jobs = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            jobs.append(a[\"title\"])\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfMKEEs5rDNl"
   },
   "outputs": [],
   "source": [
    "def extract_company(soup):\n",
    "    companies = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "        else:\n",
    "            sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-linl-source\"})\n",
    "            for span in sec_try:\n",
    "                companies.append(span.text.strip())\n",
    "    return(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onup3OzurDNt"
   },
   "outputs": [],
   "source": [
    "def extract_location(soup):\n",
    "    locations = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        try:\n",
    "            locations.append(div.find(name=\"span\", attrs={\"class\":\"location\"}).text)\n",
    "        except:\n",
    "            locations.append(\"None\")\n",
    "    return(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwxQyC4xrDN0"
   },
   "outputs": [],
   "source": [
    "def extract_salary(soup):\n",
    "    salaries = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        try:\n",
    "            salaries.append(div.find(name=\"span\", attrs={\"class\":\"salaryText\"}).text.replace(\"\\n\",\"\"))\n",
    "        except:\n",
    "            salaries.append(\"None\")\n",
    "    return(salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lG1FO5rgrDN7"
   },
   "outputs": [],
   "source": [
    "def extract_job_title(soup):\n",
    "    jobs = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            jobs.append(a[\"title\"])\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z49zqaYvrDOB"
   },
   "outputs": [],
   "source": [
    "def extract_url(soup):\n",
    "    urls = []\n",
    "    for div1 in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        for div2 in div1.find_all(name=\"div\", attrs={\"class\":\"title\"}):\n",
    "            for a in div2.find_all(name=\"a\", href=True):\n",
    "                urls.append(a['href'])\n",
    "    return(urls)\n",
    "\n",
    "def extract_desc(urls):\n",
    "    descs = []\n",
    "    for url in urls:\n",
    "        full_url = \"https://www.indeed.com\" + url\n",
    "        detail_page = requests.get(full_url)\n",
    "        detail_soup = BeautifulSoup(detail_page.text, \"html.parser\")\n",
    "        \n",
    "        for div in detail_soup.find_all(name=\"div\", attrs={\"id\":\"jobDescriptionText\"}):\n",
    "            descs.append(div.text)\n",
    "    return(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PuIAkmwirDOG"
   },
   "outputs": [],
   "source": [
    "def extract_count(soup):\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"id\":\"searchCountPages\"}):\n",
    "        temp_str = div.text.replace(\" \", \"\")\n",
    "        temp_count_str = re.search('of(.*)jobs', temp_str)\n",
    "        count_str = re.sub('[^0-9]','', temp_count_str.group(1))\n",
    "        count = int(count_str)\n",
    "    return(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apMUcrzVrDOM"
   },
   "outputs": [],
   "source": [
    "def extract_list(title_name, city_name, st_name):\n",
    "    max_results = 100\n",
    "    columns = [\"city\", \"job_title\", \"company\", \"location\", \"salary\", \"description\"]\n",
    "\n",
    "    city_url = \"https://www.indeed.com/jobs?q=\" + title_name + \\\n",
    "               \"&l=\" + city_name + \"%2C+\" + st_name\n",
    "    page = requests.get(city_url)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    max_counter = extract_count(soup)\n",
    "    print(max_counter, title_name, city_name)\n",
    "   \n",
    "    job_title_list = []\n",
    "    company_list = []\n",
    "    location_list = []\n",
    "    salary_list = []\n",
    "    desc_list = []\n",
    "\n",
    "    for start in range(0, max_results, 10):\n",
    "        city_url = \"https://www.indeed.com/jobs?q=\" + title_name + \\\n",
    "                   \"&l=\" + city_name + \"%2C+\" + st_name + \\\n",
    "                   \"&start=\" + str(start)\n",
    "        page = requests.get(city_url)\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "        job_title_list.extend(extract_job_title(soup))\n",
    "        company_list.extend(extract_company(soup))\n",
    "        location_list.extend(extract_location(soup))\n",
    "        salary_list.extend(extract_salary(soup))\n",
    "        add_urls = extract_url(soup)\n",
    "        desc_list.extend(extract_desc(add_urls))\n",
    "\n",
    "    return job_title_list, company_list, location_list, salary_list, desc_list, max_counter\n",
    "\n",
    "def job_db(title, city, st):   \n",
    "    j_list, c_list, l_list, s_list, d_list, m_counter = extract_list(title, city, st)     \n",
    "    temp_df = pd.DataFrame(list(zip(j_list, c_list, l_list, s_list, d_list)), \n",
    "                          columns = ['job_title', 'company', 'location', 'salary', 'description'])\n",
    "    temp_df['counts'] = m_counter\n",
    "    city_name = city.replace('+', ' ')\n",
    "    temp_df['city'] = city_name\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "btT5V6pSNCsj",
    "outputId": "2081c814-62f3-4385-a79f-e2121749d2ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1304 data+scientist San+Jose\n",
      "934 data+scientist San+Francisco\n",
      "1107 data+scientist Seattle\n",
      "1162 data+scientist Washington\n",
      "823 data+scientist New+York\n",
      "163 data+scientist Baltimore\n",
      "158 data+scientist Boulder\n",
      "161 data+scientist San+Diego\n",
      "175 data+scientist Denver\n",
      "21 data+scientist Huntsville\n",
      "7 data+scientist Colorado+Springs\n",
      "99 data+scientist Houston\n",
      "91 data+scientist Trenton\n",
      "450 data+scientist Dallas\n",
      "74 data+scientist Columbus\n",
      "185 data+scientist Austin\n",
      "216 data+scientist Philadelphia\n",
      "148 data+scientist Durham\n",
      "150 data+scientist Raleigh\n",
      "255 data+scientist Atlanta\n",
      "(3368, 7)\n"
     ]
    }
   ],
   "source": [
    "temp1_df = job_db('data+scientist', 'San+Jose', 'CA')\n",
    "temp2_df = job_db('data+scientist', 'San+Francisco', 'CA')\n",
    "temp3_df = job_db('data+scientist', 'Seattle', 'WA')\n",
    "temp4_df = job_db('data+scientist', 'Washington', 'DC')\n",
    "temp5_df = job_db('data+scientist', 'New+York', 'NY')\n",
    "temp6_df = job_db('data+scientist', 'Baltimore', 'MD')\n",
    "temp7_df = job_db('data+scientist', 'Boulder', 'CO')\n",
    "temp8_df = job_db('data+scientist', 'San+Diego', 'CA')\n",
    "temp9_df = job_db('data+scientist', 'Denver', 'CO')\n",
    "temp10_df = job_db('data+scientist', 'Huntsville', 'AL')\n",
    "temp11_df = job_db('data+scientist', 'Colorado+Springs', 'CO')\n",
    "temp12_df = job_db('data+scientist', 'Houston', 'TX')\n",
    "temp13_df = job_db('data+scientist', 'Trenton', 'NJ')\n",
    "temp14_df = job_db('data+scientist', 'Dallas', 'TX')\n",
    "temp15_df = job_db('data+scientist', 'Columbus', 'OH')\n",
    "temp16_df = job_db('data+scientist', 'Austin', 'TX')\n",
    "temp17_df = job_db('data+scientist', 'Philadelphia', 'PA')\n",
    "temp18_df = job_db('data+scientist', 'Durham', 'NC')\n",
    "temp19_df = job_db('data+scientist', 'Raleigh', 'NC')\n",
    "temp20_df = job_db('data+scientist', 'Atlanta', 'GA')\n",
    "\n",
    "data_scientist_df = pd.concat([temp1_df, temp2_df, temp3_df, temp4_df, temp5_df,\n",
    "                       temp6_df, temp7_df, temp8_df, temp9_df, temp10_df,\n",
    "                       temp11_df, temp12_df, temp13_df, temp14_df, temp15_df,\n",
    "                       temp16_df, temp17_df, temp18_df, temp19_df, temp20_df], ignore_index=True)\n",
    "\n",
    "print(data_scientist_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "QtJLD1unfnnG",
    "outputId": "a001cad1-3315-4d72-b7ae-5dd64a22428c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1371 web+developer San+Jose\n",
      "1415 web+developer San+Francisco\n",
      "1417 web+developer Seattle\n",
      "3385 web+developer Washington\n",
      "1821 web+developer New+York\n",
      "877 web+developer Baltimore\n",
      "438 web+developer Boulder\n",
      "363 web+developer San+Diego\n",
      "596 web+developer Denver\n",
      "78 web+developer Huntsville\n",
      "68 web+developer Colorado+Springs\n",
      "368 web+developer Houston\n",
      "223 web+developer Trenton\n",
      "771 web+developer Dallas\n",
      "225 web+developer Columbus\n",
      "656 web+developer Austin\n",
      "530 web+developer Philadelphia\n",
      "384 web+developer Durham\n",
      "367 web+developer Raleigh\n",
      "(3623, 7)\n"
     ]
    }
   ],
   "source": [
    "temp1_df = job_db('web+developer', 'San+Jose', 'CA')\n",
    "temp2_df = job_db('web+developer', 'San+Francisco', 'CA')\n",
    "temp3_df = job_db('web+developer', 'Seattle', 'WA')\n",
    "temp4_df = job_db('web+developer', 'Washington', 'DC')\n",
    "temp5_df = job_db('web+developer', 'New+York', 'NY')\n",
    "temp6_df = job_db('web+developer', 'Baltimore', 'MD')\n",
    "temp7_df = job_db('web+developer', 'Boulder', 'CO')\n",
    "temp8_df = job_db('web+developer', 'San+Diego', 'CA')\n",
    "temp9_df = job_db('web+developer', 'Denver', 'CO')\n",
    "temp10_df = job_db('web+developer', 'Huntsville', 'AL')\n",
    "temp11_df = job_db('web+developer', 'Colorado+Springs', 'CO')\n",
    "temp12_df = job_db('web+developer', 'Houston', 'TX')\n",
    "temp13_df = job_db('web+developer', 'Trenton', 'NJ')\n",
    "temp14_df = job_db('web+developer', 'Dallas', 'TX')\n",
    "temp15_df = job_db('web+developer', 'Columbus', 'OH')\n",
    "temp16_df = job_db('web+developer', 'Austin', 'TX')\n",
    "temp17_df = job_db('web+developer', 'Philadelphia', 'PA')\n",
    "temp18_df = job_db('web+developer', 'Durham', 'NC')\n",
    "temp19_df = job_db('web+developer', 'Raleigh', 'NC')\n",
    "\n",
    "web_developer_df = pd.concat([temp1_df, temp2_df, temp3_df, temp4_df, temp5_df,\n",
    "                              temp6_df, temp7_df, temp8_df, temp9_df, temp10_df,\n",
    "                              temp11_df, temp12_df, temp13_df, temp14_df, temp15_df,\n",
    "                              temp16_df, temp17_df, temp18_df, temp19_df, temp20_df], ignore_index=True)\n",
    "print(web_developer_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "kxjzVabzmpRJ",
    "outputId": "b944820a-43d7-4f5e-e4fd-0cf9a22a33bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633 ux+designer San+Jose\n",
      "872 ux+designer San+Francisco\n",
      "944 ux+designer Seattle\n",
      "522 ux+designer Washington\n",
      "870 ux+designer New+York\n",
      "88 ux+designer Baltimore\n",
      "132 ux+designer Boulder\n",
      "105 ux+designer San+Diego\n",
      "146 ux+designer Denver\n",
      "8 ux+designer Huntsville\n",
      "6 ux+designer Colorado+Springs\n",
      "82 ux+designer Houston\n",
      "41 ux+designer Trenton\n",
      "177 ux+designer Dallas\n",
      "47 ux+designer Columbus\n",
      "275 ux+designer Austin\n",
      "145 ux+designer Philadelphia\n",
      "83 ux+designer Durham\n",
      "83 ux+designer Raleigh\n",
      "252 ux+designer Atlanta\n",
      "(3099, 7)\n"
     ]
    }
   ],
   "source": [
    "temp1_df = job_db('ux+designer', 'San+Jose', 'CA')\n",
    "temp2_df = job_db('ux+designer', 'San+Francisco', 'CA')\n",
    "temp3_df = job_db('ux+designer', 'Seattle', 'WA')\n",
    "temp4_df = job_db('ux+designer', 'Washington', 'DC')\n",
    "temp5_df = job_db('ux+designer', 'New+York', 'NY')\n",
    "temp6_df = job_db('ux+designer', 'Baltimore', 'MD')\n",
    "temp7_df = job_db('ux+designer', 'Boulder', 'CO')\n",
    "temp8_df = job_db('ux+designer', 'San+Diego', 'CA')\n",
    "temp9_df = job_db('ux+designer', 'Denver', 'CO')\n",
    "temp10_df = job_db('ux+designer', 'Huntsville', 'AL')\n",
    "temp11_df = job_db('ux+designer', 'Colorado+Springs', 'CO')\n",
    "temp12_df = job_db('ux+designer', 'Houston', 'TX')\n",
    "temp13_df = job_db('ux+designer', 'Trenton', 'NJ')\n",
    "temp14_df = job_db('ux+designer', 'Dallas', 'TX')\n",
    "temp15_df = job_db('ux+designer', 'Columbus', 'OH')\n",
    "temp16_df = job_db('ux+designer', 'Austin', 'TX')\n",
    "temp17_df = job_db('ux+designer', 'Philadelphia', 'PA')\n",
    "temp18_df = job_db('ux+designer', 'Durham', 'NC')\n",
    "temp19_df = job_db('ux+designer', 'Raleigh', 'NC')\n",
    "temp20_df = job_db('ux+designer', 'Atlanta', 'GA')\n",
    "\n",
    "ux_designer_df = pd.concat([temp1_df, temp2_df, temp3_df, temp4_df, temp5_df,\n",
    "                            temp6_df, temp7_df, temp8_df, temp9_df, temp10_df,\n",
    "                            temp11_df, temp12_df, temp13_df, temp14_df, temp15_df,\n",
    "                            temp16_df, temp17_df, temp18_df, temp19_df, temp20_df], ignore_index=True)\n",
    "print(ux_designer_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "PIxfH9yfnheV",
    "outputId": "e9773928-1b3d-45a2-f6e5-28954b09f4e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751 ios+developer San+Jose\n",
      "468 ios+developer San+Francisco\n",
      "484 ios+developer Seattle\n",
      "351 ios+developer Washington\n",
      "377 ios+developer New+York\n",
      "82 ios+developer Baltimore\n",
      "106 ios+developer Boulder\n",
      "83 ios+developer San+Diego\n",
      "129 ios+developer Denver\n",
      "15 ios+developer Huntsville\n",
      "6 ios+developer Colorado+Springs\n",
      "53 ios+developer Houston\n",
      "24 ios+developer Trenton\n",
      "153 ios+developer Dallas\n",
      "28 ios+developer Columbus\n",
      "174 ios+developer Austin\n",
      "88 ios+developer Philadelphia\n",
      "47 ios+developer Durham\n",
      "46 ios+developer Raleigh\n",
      "142 ios+developer Atlanta\n",
      "(3185, 7)\n"
     ]
    }
   ],
   "source": [
    "temp1_df = job_db('ios+developer', 'San+Jose', 'CA')\n",
    "temp2_df = job_db('ios+developer', 'San+Francisco', 'CA')\n",
    "temp3_df = job_db('ios+developer', 'Seattle', 'WA')\n",
    "temp4_df = job_db('ios+developer', 'Washington', 'DC')\n",
    "temp5_df = job_db('ios+developer', 'New+York', 'NY')\n",
    "temp6_df = job_db('ios+developer', 'Baltimore', 'MD')\n",
    "temp7_df = job_db('ios+developer', 'Boulder', 'CO')\n",
    "temp8_df = job_db('ios+developer', 'San+Diego', 'CA')\n",
    "temp9_df = job_db('ios+developer', 'Denver', 'CO')\n",
    "temp10_df = job_db('ios+developer', 'Huntsville', 'AL')\n",
    "temp11_df = job_db('ios+developer', 'Colorado+Springs', 'CO')\n",
    "temp12_df = job_db('ios+developer', 'Houston', 'TX')\n",
    "temp13_df = job_db('ios+developer', 'Trenton', 'NJ')\n",
    "temp14_df = job_db('ios+developer', 'Dallas', 'TX')\n",
    "temp15_df = job_db('ios+developer', 'Columbus', 'OH')\n",
    "temp16_df = job_db('ios+developer', 'Austin', 'TX')\n",
    "temp17_df = job_db('ios+developer', 'Philadelphia', 'PA')\n",
    "temp18_df = job_db('ios+developer', 'Durham', 'NC')\n",
    "temp19_df = job_db('ios+developer', 'Raleigh', 'NC')\n",
    "temp20_df = job_db('ios+developer', 'Atlanta', 'GA')\n",
    "\n",
    "ios_developer_df = pd.concat([temp1_df, temp2_df, temp3_df, temp4_df, temp5_df,\n",
    "                              temp6_df, temp7_df, temp8_df, temp9_df, temp10_df,\n",
    "                              temp11_df, temp12_df, temp13_df, temp14_df, temp15_df,\n",
    "                              temp16_df, temp17_df, temp18_df, temp19_df, temp20_df], ignore_index=True)\n",
    "print(ios_developer_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxO8nLwjrDOR"
   },
   "outputs": [],
   "source": [
    "data_scientist_df['job'] = 'data scientist'\n",
    "web_developer_df['job'] = 'web developer'\n",
    "ux_designer_df['job'] = 'ux designer'\n",
    "ios_developer_df['job'] = 'ios developer'\n",
    "indeed_df = pd.concat([data_scientist_df, web_developer_df, ux_designer_df, ios_developer_df], ignore_index=True)\n",
    "indeed_df = indeed_df.drop_duplicates(keep=False) \n",
    "indeed_df = indeed_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "iQtq-mjCrDOW",
    "outputId": "5adc8dc3-5440-46e0-87af-761a56dbbd09"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>counts</th>\n",
       "      <th>city</th>\n",
       "      <th>job</th>\n",
       "      <th>low_salary</th>\n",
       "      <th>high_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist (All Levels) - Santa Clara</td>\n",
       "      <td>LeanTaaS</td>\n",
       "      <td>Santa Clara, CA 95050</td>\n",
       "      <td>Help build technology that saves lives!\\n\\nWe'...</td>\n",
       "      <td>1304</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Palo Verde Consulting</td>\n",
       "      <td>Campbell, CA 95008</td>\n",
       "      <td>Job Title: Data ScientistLocation: Campbell, C...</td>\n",
       "      <td>1304</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>210000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Spry Health</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>Spry Health’s mission is to build the world’s ...</td>\n",
       "      <td>1304</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>SLEEP NUMBER</td>\n",
       "      <td>San Jose, CA 95123 (Blossom Valley area)</td>\n",
       "      <td>Position Purpose:\\nAs Data Scientist, you will...</td>\n",
       "      <td>1304</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist in Santa Clara, CA (corp-corp c...</td>\n",
       "      <td>Advantine Technologies</td>\n",
       "      <td>Santa Clara, CA</td>\n",
       "      <td>Job Description\\n\\nTitle : Data Scientist\\nLoc...</td>\n",
       "      <td>1304</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  ... high_salary\n",
       "0          Data Scientist (All Levels) - Santa Clara  ...         NaN\n",
       "1                                     Data Scientist  ...    210000.0\n",
       "2                                     Data Scientist  ...    135000.0\n",
       "3                                     Data Scientist  ...         NaN\n",
       "4  Data Scientist in Santa Clara, CA (corp-corp c...  ...         NaN\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_salary(sal_str, s_flag):\n",
    "    \n",
    "    sal_split = re.findall(r'\\d+', sal_str.replace(\",\", \"\"))\n",
    "    \n",
    "    if len(sal_split) == 2:\n",
    "        low_salary = int(sal_split[0])\n",
    "        high_salary = int(sal_split[1])\n",
    "    else:\n",
    "        low_salary = None\n",
    "        high_salary = None\n",
    "    \n",
    "    if s_flag == 'l':\n",
    "        salary = low_salary\n",
    "    else:\n",
    "        salary = high_salary\n",
    "    \n",
    "    return salary\n",
    "\n",
    "indeed_df['low_salary'] = indeed_df.apply(lambda x: convert_salary(x['salary'], 'l'), axis=1)\n",
    "indeed_df['high_salary'] = indeed_df.apply(lambda x: convert_salary(x['salary'], 'h'), axis=1)\n",
    "indeed_df = indeed_df.drop(columns=['salary'])\n",
    "\n",
    "indeed_df.head()                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "mQ8FO9aaixTW",
    "outputId": "401ac5af-e88b-4d8c-abeb-01046f9ea3cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>counts</th>\n",
       "      <th>city</th>\n",
       "      <th>job</th>\n",
       "      <th>low_salary</th>\n",
       "      <th>high_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>Senior Software Engineer</td>\n",
       "      <td>MDT Software</td>\n",
       "      <td>Alpharetta, GA 30005</td>\n",
       "      <td>MDT is seeking a Senior Software Engineer who ...</td>\n",
       "      <td>142</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>ios developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>ASSA ABLOY Opening Solutions</td>\n",
       "      <td>Marietta, GA</td>\n",
       "      <td>HID Global powers the trusted identities of th...</td>\n",
       "      <td>142</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>ios developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Assa Abloy</td>\n",
       "      <td>Marietta, GA</td>\n",
       "      <td>HID Global powers the trusted identities of th...</td>\n",
       "      <td>142</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>ios developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>Devops Engineer</td>\n",
       "      <td>MacStadium</td>\n",
       "      <td>Atlanta, GA 30305 (Buckhead area)</td>\n",
       "      <td>Overview\\nMacStadium is the leading managed Ma...</td>\n",
       "      <td>142</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>ios developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4800</th>\n",
       "      <td>Sr. UX Designer</td>\n",
       "      <td>Cooper Holdings, Inc.</td>\n",
       "      <td>Atlanta, GA 30339</td>\n",
       "      <td>You Are Here (YAH) is a creative agency built ...</td>\n",
       "      <td>142</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>ios developer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     job_title  ... high_salary\n",
       "4796  Senior Software Engineer  ...         NaN\n",
       "4797         Software Engineer  ...         NaN\n",
       "4798         Software Engineer  ...         NaN\n",
       "4799           Devops Engineer  ...         NaN\n",
       "4800           Sr. UX Designer  ...         NaN\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejMqC3iJrDOt"
   },
   "outputs": [],
   "source": [
    "# convert to sqlite3 and csv\n",
    "conn = sqlite3.connect('techsearch.sqlite3')\n",
    "curs = conn.cursor()\n",
    "curs.execute('drop table if exists listings')\n",
    "indeed_df.to_sql('listings', con=conn)\n",
    "indeed_df.to_csv('/content/techsearch.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "scrape.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp-1 (Python3)",
   "language": "python",
   "name": "nlp-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
