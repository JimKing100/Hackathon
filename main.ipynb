{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled57.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JimKing100/Hackathon/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX51dhr4oyC_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "d37d1913-84ca-498b-8110-ab893901faea"
      },
      "source": [
        "!pip install squarify"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting squarify\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/2b/2e77c35326efec19819cd1d729540d4d235e6c2a3f37658288a363a67da5/squarify-0.4.3-py3-none-any.whl\n",
            "Installing collected packages: squarify\n",
            "Successfully installed squarify-0.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22kkF7k7ono9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "import squarify\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import html as ihtml\n",
        "\n",
        "import requests\n",
        "import sqlite3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwfJM8m5o3Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indeed_df = pd.read_csv('https://raw.githubusercontent.com/JimKing100/Hackathon/master/data/techsearch.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmLzkR1vn51j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "d9f9d38c-e98d-4c37-e6a1-70131402ecf0"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.replace('\\n', ' ')                # remove newline\n",
        "    text = BeautifulSoup(text, \"lxml\").get_text() # remove html\n",
        "    text = text.replace('/', ' ')                 # remove forward slashes\n",
        "    text = re.sub(r'[^a-zA-Z ^0-9]', '', text)    # letters and numbers only\n",
        "    text = text.lower()                           # lower case\n",
        "    text = re.sub(r'(x.[0-9])', '', text)         # remove special characters\n",
        "    return text\n",
        "\n",
        "indeed_df['description'] = indeed_df.apply(lambda x: clean_text(x['description']), axis=1)\n",
        "\n",
        "indeed_df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>job_title</th>\n",
              "      <th>company</th>\n",
              "      <th>location</th>\n",
              "      <th>description</th>\n",
              "      <th>counts</th>\n",
              "      <th>city</th>\n",
              "      <th>job</th>\n",
              "      <th>low_salary</th>\n",
              "      <th>high_salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Pactera</td>\n",
              "      <td>None</td>\n",
              "      <td>looking fora data scientis architect who has 8...</td>\n",
              "      <td>1319</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Data scientist - Global Sales</td>\n",
              "      <td>PayPal</td>\n",
              "      <td>None</td>\n",
              "      <td>responsibilities  provide business requirement...</td>\n",
              "      <td>1319</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Palo Verde Consulting</td>\n",
              "      <td>Campbell, CA 95008 (Central Campbell area)</td>\n",
              "      <td>job title data scientistlocation campbell ca 9...</td>\n",
              "      <td>1319</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>150000.0</td>\n",
              "      <td>210000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Spry Health</td>\n",
              "      <td>Palo Alto, CA</td>\n",
              "      <td>spry healths mission is to build the worlds la...</td>\n",
              "      <td>1319</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>135000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Data Scientist (All Levels) - Santa Clara</td>\n",
              "      <td>LeanTaaS</td>\n",
              "      <td>Santa Clara, CA 95050</td>\n",
              "      <td>help build technology that saves lives  were a...</td>\n",
              "      <td>1319</td>\n",
              "      <td>San Jose</td>\n",
              "      <td>data scientist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... high_salary\n",
              "0           0  ...         NaN\n",
              "1           1  ...         NaN\n",
              "2           2  ...    210000.0\n",
              "3           3  ...    135000.0\n",
              "4           4  ...         NaN\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDc8aHDuoBKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0636c4b7-bace-453a-8e93-88518dfd3db8"
      },
      "source": [
        "indeed_df['description'][10]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fiveby is a highend antifraud and online security consultancy headquartered in seattle with operations across the united states we are a motivated group of specialized professionals united under the mission to provide the programs services and expertise our clients need to protect their products and customers with the everincreasing risk of security breaches identity fraud espionage online attacks and other nefarious activities by bad actors there has never been a better time to join the fight against online crime were on the search for a junior data scientist to join our ranks this position will embed with our existing clientsite team in menlo park and will partner closely with our bi analyst to support data analytics and reporting for antifraud operations this role will be responsible for identifying cleaning extracting data linking dataset relationships from existing sources and building accessible tools and dashboards for use by stakeholders across functions this role is seated with our client in menlo park this is not a remote or workfromhome position this position will be responsible for identifying appropriate datasets needed for decision making partnering with the teams bi analyst to build processes for data extraction cleaning analysis and visualization collecting deconstructing analyzing testing visualizing and modeling data to predict user behavior automating data collection and building advanced analytics solutions tools dashboards from complex and often disparate data sets formulating recommendations based on findings and expertise requirements for this role include a bachelors degree or higher preferably in mathematics statistics economics or computer science 12 years of experience in a large enterprise data environment high level of proficiency in sql r and python high level of proficiency in tableau powerbi looker or similar familiarity with machine learning familiarity with data pipeline and assessment of data integrity complex problem solving skills including the ability to see connections between available data and user behavior preferred qualifications experience in the antifraud antipiracy space successful fiveby consultants also have adaptable communication skills an entrepreneurial spirit a passion for collaborative problem solving continuous learning and team success fiveby is an equal opportunity employer all employment decisions  including the decision to hire promote discipline or discharge  are based on merit competence performance and business needs we do not discriminate based on race color religion marital status age national origin ancestry physical or mental disability medical condition pregnancy genetic information gender sexual orientation gender identity or expression veteran status or any other status protected under federal state or local law work environment and physical demands in order to perform this role the selected employee must be able to operate within a standard office environment with or without reasonable accommodation this includes the ability to withstand long periods of staring at a computer screen exposure to fluorescent lights and repetitive motion associated with writing and or continuous computer use this role requires the ability to stand or sit for long periods of time communicate with others via speech or text and use hands or other tools to operate a computer and keyboard light to moderate lifting may be required due to the nature of our work employees must be able to uphold the stress of traveling to client sites as well as adapt within reason to the conditions of client sites regular predictable attendance is required as is the ability to work outside of standard business hours as business needs dictate accommodation if you require accommodation due to a documented disability covered under the americans disability act click here to submit your accommodation request to be eligible for accommodation under the ada applicants must meet the minimum qualifications of the position for which they are applying  tjuterd'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}