{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "nlp-1 (Python3)",
      "language": "python",
      "name": "nlp-1"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "scrape.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yh0CiJnRsBXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15db8003-2647-46b4-a8ff-67fb8a27c542"
      },
      "source": [
        "!pip install squarify"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: squarify in /usr/local/lib/python3.6/dist-packages (0.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y133qOkzrDND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "import squarify\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import html as ihtml\n",
        "\n",
        "import requests\n",
        "import sqlite3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCvFe_74rDNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_job_title(soup):\n",
        "    jobs = []\n",
        "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
        "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
        "            jobs.append(a[\"title\"])\n",
        "    return(jobs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfMKEEs5rDNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_company(soup):\n",
        "    companies = []\n",
        "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
        "        company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
        "        if len(company) > 0:\n",
        "            for b in company:\n",
        "                companies.append(b.text.strip())\n",
        "        else:\n",
        "            sec_try = div.find_all(name=\"span\", attrs={\"class\":\"result-linl-source\"})\n",
        "            for span in sec_try:\n",
        "                companies.append(span.text.strip())\n",
        "    return(companies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onup3OzurDNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_location(soup):\n",
        "    locations = []\n",
        "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
        "        try:\n",
        "            locations.append(div.find(name=\"span\", attrs={\"class\":\"location\"}).text)\n",
        "        except:\n",
        "            locations.append(\"None\")\n",
        "    return(locations)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwxQyC4xrDN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_salary(soup):\n",
        "    salaries = []\n",
        "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
        "        try:\n",
        "            salaries.append(div.find(name=\"span\", attrs={\"class\":\"salaryText\"}).text.replace(\"\\n\",\"\"))\n",
        "        except:\n",
        "            salaries.append(\"None\")\n",
        "    return(salaries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG1FO5rgrDN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_job_title(soup):\n",
        "    jobs = []\n",
        "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
        "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
        "            jobs.append(a[\"title\"])\n",
        "    return(jobs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z49zqaYvrDOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_url(soup):\n",
        "    urls = []\n",
        "    for div1 in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
        "        for div2 in div1.find_all(name=\"div\", attrs={\"class\":\"title\"}):\n",
        "            for a in div2.find_all(name=\"a\", href=True):\n",
        "                urls.append(a['href'])\n",
        "    return(urls)\n",
        "\n",
        "def extract_desc(urls):\n",
        "    descs = []\n",
        "    for url in urls:\n",
        "        full_url = \"https://www.indeed.com\" + url\n",
        "        detail_page = requests.get(full_url)\n",
        "        detail_soup = BeautifulSoup(detail_page.text, \"html.parser\")\n",
        "        \n",
        "        for div in detail_soup.find_all(name=\"div\", attrs={\"id\":\"jobDescriptionText\"}):\n",
        "            descs.append(div.text)\n",
        "    return(descs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuIAkmwirDOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_count(soup):\n",
        "    for div in soup.find_all(name=\"div\", attrs={\"id\":\"searchCountPages\"}):\n",
        "        temp_str = div.text.replace(\" \", \"\")\n",
        "        temp_count_str = re.search('of(.*)jobs', temp_str)\n",
        "        count_str = re.sub('[^0-9]','', temp_count_str.group(1))\n",
        "        count = int(count_str)\n",
        "    return(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apMUcrzVrDOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "bf5fb34c-2a5f-41fd-bac6-fb94453efa70"
      },
      "source": [
        "def extract_list(title_name, city_name, st_name):\n",
        "    max_results = 10\n",
        "    columns = [\"city\", \"job_title\", \"company\", \"location\", \"salary\", \"description\"]\n",
        "\n",
        "    city_url = \"https://www.indeed.com/jobs?q=\" + title_name + \\\n",
        "               \"&l=\" + city_name + \"%2C+\" + st_name\n",
        "    page = requests.get(city_url)\n",
        "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
        "    max_counter = extract_count(soup)\n",
        "    print(max_counter)\n",
        "\n",
        "    job_title_list = []\n",
        "    company_list = []\n",
        "    location_list = []\n",
        "    salary_list = []\n",
        "    desc_list = []\n",
        "\n",
        "    for start in range(0, max_results, 10):\n",
        "        city_url = \"https://www.indeed.com/jobs?q=\" + title_name + \\\n",
        "                   \"&l=\" + city_name + \"%2C+\" + st_name + \\\n",
        "                   \"&start=\" + str(start)\n",
        "        print(city_url)\n",
        "        page = requests.get(city_url)\n",
        "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
        "\n",
        "        job_title_list.extend(extract_job_title(soup))\n",
        "        company_list.extend(extract_company(soup))\n",
        "        location_list.extend(extract_location(soup))\n",
        "        salary_list.extend(extract_salary(soup))\n",
        "        add_urls = extract_url(soup)\n",
        "        desc_list.extend(extract_desc(add_urls))\n",
        "\n",
        "    return job_title_list, company_list, location_list, salary_list, desc_list\n",
        "\n",
        "def job_db(title, city, st):   \n",
        "    j_list, c_list, l_list, s_list, d_list = extract_list(title, city, st)     \n",
        "    temp_df = pd.DataFrame(list(zip(j_list, c_list, l_list, s_list, d_list)), \n",
        "                          columns = ['job_title', 'company', 'location', 'salary', 'description'])\n",
        "    return temp_df\n",
        "\n",
        "temp1_df = job_db('data+scientist', 'San+Jose', 'CA')\n",
        "temp2_df = job_db('data+scientist', 'San+Francisco', 'CA')\n",
        "temp3_df = job_db('data+scientist', 'Seattle', 'WA')\n",
        "temp4_df = job_db('data+scientist', 'Washington', 'DC')\n",
        "temp5_df = job_db('data+scientist', 'New+York', 'NY')\n",
        "temp6_df = job_db('data+scientist', 'Baltimore', 'MD')\n",
        "temp7_df = job_db('data+scientist', 'Boulder', 'CO')\n",
        "temp8_df = job_db('data+scientist', 'San+Diego', 'CA')\n",
        "temp9_df = job_db('data+scientist', 'Denver', 'CO')\n",
        "temp10_df = job_db('data+scientist', 'Huntsville', 'AL')\n",
        "temp11_df = job_db('data+scientist', 'Colorado+Springs', 'CO')\n",
        "temp12_df = job_db('data+scientist', 'Houston', 'TX')\n",
        "temp13_df = job_db('data+scientist', 'Trenton', 'NJ')\n",
        "temp14_df = job_db('data+scientist', 'Dallas', 'TX')\n",
        "temp15_df = job_db('data+scientist', 'Columbus', 'OH')\n",
        "temp16_df = job_db('data+scientist', 'Austin', 'TX')\n",
        "temp17_df = job_db('data+scientist', 'Philadelphia', 'PA')\n",
        "temp18_df = job_db('data+scientist', 'Durham', 'NC')\n",
        "temp19_df = job_db('data+scientist', 'Raleigh', 'NC')\n",
        "temp20_df = job_db('data+scientist', 'Atlanta', 'GA')\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1314\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=San+Jose%2C+CA&start=0\n",
            "939\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=San+Francisco%2C+CA&start=0\n",
            "1107\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Seattle%2C+WA&start=0\n",
            "1173\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Washington%2C+DC&start=0\n",
            "824\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=New+York%2C+NY&start=0\n",
            "163\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Baltimore%2C+MD&start=0\n",
            "161\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Boulder%2C+CO&start=0\n",
            "160\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=San+Diego%2C+CA&start=0\n",
            "181\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Denver%2C+CO&start=0\n",
            "23\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Huntsville%2C+AL&start=0\n",
            "10\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Colorado+Springs%2C+CO&start=0\n",
            "98\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Houston%2C+TX&start=0\n",
            "92\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Trenton%2C+NJ&start=0\n",
            "252\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Dallas%2C+TX&start=0\n",
            "73\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Columbus%2C+OH&start=0\n",
            "183\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Austin%2C+TX&start=0\n",
            "214\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Philadelphia%2C+PA&start=0\n",
            "143\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Durham%2C+NC&start=0\n",
            "145\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Raleigh%2C+NC&start=0\n",
            "260\n",
            "https://www.indeed.com/jobs?q=data+scientist&l=Atlanta%2C+GA&start=0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btT5V6pSNCsj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6922385-1dde-430d-f44a-1bac01731dc3"
      },
      "source": [
        "indeed_df = pd.concat([temp1_df, temp2_df, temp3_df, temp4_df, temp5_df,\n",
        "                       temp6_df, temp7_df, temp8_df, temp9_df, temp10_df,\n",
        "                       temp11_df, temp12_df, temp13_df, temp14_df, temp15_df,\n",
        "                       temp16_df, temp17_df, temp18_df, temp19_df, temp20_df], ignore_index=True)\n",
        "print(indeed_df.shape)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(197, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxO8nLwjrDOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indeed_df = indeed_df.drop_duplicates(keep=False) \n",
        "indeed_df = indeed_df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQtq-mjCrDOW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "95a889b4-e07d-4376-89ba-ff23fa28b4a5"
      },
      "source": [
        "def convert_salary(sal_str, s_flag):\n",
        "    \n",
        "    sal_split = re.findall(r'\\d+', sal_str.replace(\",\", \"\"))\n",
        "    \n",
        "    if len(sal_split) == 2:\n",
        "        low_salary = int(sal_split[0])\n",
        "        high_salary = int(sal_split[1])\n",
        "    else:\n",
        "        low_salary = None\n",
        "        high_salary = None\n",
        "    \n",
        "    if s_flag == 'l':\n",
        "        salary = low_salary\n",
        "    else:\n",
        "        salary = high_salary\n",
        "    \n",
        "    return salary\n",
        "\n",
        "indeed_df['low_salary'] = indeed_df.apply(lambda x: convert_salary(x['salary'], 'l'), axis=1)\n",
        "indeed_df['high_salary'] = indeed_df.apply(lambda x: convert_salary(x['salary'], 'h'), axis=1)\n",
        "indeed_df = indeed_df.drop(columns=['salary'])\n",
        "\n",
        "indeed_df.head()                                      "
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_title</th>\n",
              "      <th>company</th>\n",
              "      <th>location</th>\n",
              "      <th>description</th>\n",
              "      <th>low_salary</th>\n",
              "      <th>high_salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Siri - Data Scientist, Data Organization</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Santa Clara Valley, CA 95014</td>\n",
              "      <td>Summary\\nPosted: Dec 6, 2019\\nWeekly Hours: 40...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>SLEEP NUMBER</td>\n",
              "      <td>San Jose, CA 95123 (Blossom Valley area)</td>\n",
              "      <td>Position Purpose:\\nAs Data Scientist, you will...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Spry Health</td>\n",
              "      <td>Palo Alto, CA</td>\n",
              "      <td>Spry Health’s mission is to build the world’s ...</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>135000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>PayPal</td>\n",
              "      <td>San Jose, CA 95131 (North San Jose area)</td>\n",
              "      <td>This role is in the Global Resolutions and Pro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Ford Motor Company</td>\n",
              "      <td>Palo Alto, CA</td>\n",
              "      <td>Data Scientist\\n\\n\\nJob description:\\n\\n\\nData...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  job_title  ... high_salary\n",
              "0  Siri - Data Scientist, Data Organization  ...         NaN\n",
              "1                            Data Scientist  ...         NaN\n",
              "2                            Data Scientist  ...    135000.0\n",
              "3                            Data Scientist  ...         NaN\n",
              "4                            Data Scientist  ...         NaN\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeG9aHa4rDOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c8abecc0-4ab0-46fa-b393-ac381fd9aefb"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.replace('\\\\n', ' ')               # remove newline\n",
        "    text = BeautifulSoup(text, \"lxml\").get_text() # remove html\n",
        "    text = text.replace('/', ' ')                 # remove forward slashes\n",
        "    text = re.sub(r'[^a-zA-Z ^0-9]', '', text)    # letters and numbers only\n",
        "    text = text.lower()                           # lower case\n",
        "    text = re.sub(r'(x.[0-9])', '', text)         # remove special characters\n",
        "    return text\n",
        "\n",
        "indeed_df['description'] = indeed_df.apply(lambda x: clean_text(x['description']), axis=1)\n",
        "\n",
        "indeed_df.head()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>job_title</th>\n",
              "      <th>company</th>\n",
              "      <th>location</th>\n",
              "      <th>description</th>\n",
              "      <th>low_salary</th>\n",
              "      <th>high_salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Siri - Data Scientist, Data Organization</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Santa Clara Valley, CA 95014</td>\n",
              "      <td>summaryposted dec 6 2019weekly hours 40role nu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>SLEEP NUMBER</td>\n",
              "      <td>San Jose, CA 95123 (Blossom Valley area)</td>\n",
              "      <td>position purposeas data scientist you will pla...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Spry Health</td>\n",
              "      <td>Palo Alto, CA</td>\n",
              "      <td>spry healths mission is to build the worlds la...</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>135000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>PayPal</td>\n",
              "      <td>San Jose, CA 95131 (North San Jose area)</td>\n",
              "      <td>this role is in the global resolutions and pro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Ford Motor Company</td>\n",
              "      <td>Palo Alto, CA</td>\n",
              "      <td>data scientistjob descriptiondata scientist po...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  job_title  ... high_salary\n",
              "0  Siri - Data Scientist, Data Organization  ...         NaN\n",
              "1                            Data Scientist  ...         NaN\n",
              "2                            Data Scientist  ...    135000.0\n",
              "3                            Data Scientist  ...         NaN\n",
              "4                            Data Scientist  ...         NaN\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m41bi-PFrDOj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "94c98420-b857-4ff9-cfde-5639a0b24fd5"
      },
      "source": [
        "indeed_df['description'][0]"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'summaryposted dec 6 2019weekly hours 40role number200125352would you like to play a part in the next revolution in humancomputer interaction contribute to a product that is redefining mobile and desktop computing and work with the people who built the intelligent assistant that helps millions of people get things done  just by askingthe vision for the siri data organization is to improve siri by using data as the voice of our customers within this organization the mission of the analytics team is to inform the evolution of siri through measurement and analysis of the user experience as a data scientist on the team you will be an ambassador of analytics to language understanding product and engineering teams with the ultimate purpose of improving the siri experience for apple customerskey qualificationsyou think about language and complex systems in terms of statistical distributions and have a big enough toolbox to know how to find patterns in data identify targets for performance and identify sources of variance about those targetsyou use good judgment balancing art and science when visually communicating information eg tableau superset ggplot d3 matplotlib plotly bokehyou have engineered information out of massive and complex datasets eg hive spark druid elasticsearch solryou have proven experience with at least one programming language eg python r scala and are comfortable developing code in a team environment eg git notebooks testingyou are selfmotivated and curious with demonstrated creative and critical thinking capabilities and an innate drive to improve how things workyou have a high tolerance for ambiguity you find a way through you anticipate you connect and synthesizeyou have excellent verbal and written communications skills and experience in influencing decisions with informationyour academic background is in a quantitative field such as computer science computational linguistics mathematics statistics engineering economics or physics advanced degree preferreddescriptionpartner with multiple languageunderstanding and product engineering teams to understand systemic behavior of siri and develop methods for evaluating component and model interactions bias propagation and hierarchical optimizationdefine metrics that we will measure our efforts against as well as defining the instrumentation required for yielding sufficient datacommunicate with and advocate to a wide audience of engineers managers and executives to inform decisions on how siris capabilities evolvebuild analytic visualization and other information products with a drive to automate and scale the insights available to science and engineering teamsperform exploratory data analyses to enrich our mental models about siri usage and identify new questions to pursueextract information from structured and unstructured data coming from siris computational architecturewe are looking for people with a track record in building insights and relationships to affect decisions join us and impact hundreds of millions of customers across billions of their interactions with a personal intelligent assistant who is available on iphone ipad homepod watch tv and mac across more than 30 languagesadditional requirementsapple is an equal opportunity employer that is committed to inclusion and diversity we take affirmative action to ensure equal opportunity for all applicants without regard to race color religion sex sexual orientation gender identity national origin disability veteran status or other legally protected characteristics'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFQOeIHCrDOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "982ed281-3a45-4937-a745-2c0993f506e6"
      },
      "source": [
        "indeed_df['description'][4]"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data scientistjob descriptiondata scientist positions offered by ford motor company palo alto ca build machine learning models to solve business problems perform data acquisition and cleaning data exploration hypothesis formation and testing experimental design and custom software developmentminimum requirementsmasters or foreign equivalent degree in industrial engineering computer science or a related field3 years of experience in the position offered or 3 years of experience in automotive industry supporting business units with machine learning and deep learning techniques3 years of experience developing machine learning models with a focus on text analytics applications with natural language processing techniques including parsing word embeddings clustering cosine distance similarity metrics language modeling and ontologies3 years of experience performing hypothesis testing and inference probability distributions confidence intervals and pvalues3 years of experience working in hadoop ecosystem and distributed cluster computing3 years of experience working in linux unix systems3 years of experience using relational databases and sql programming2 years of experience performing webbased development2 years of experience using software development methodologies including waterfall and agile2 years of experience building supervised and unsupervised models with scikitlearn and sparkml and training neural networks with gradient descent optimization on machine learning platforms1 year of experience using containerization technologies experience may be but need not be acquired concurrentlyjoin our team as we create tomorrow we believe in putting people first working together and facing challenges headon because were built ford tough were one team striving to make peoples lives better while creating value delivering excellence and ultimately going for the winford motor company is an equal opportunity employer committed to a culturally diverse workforce all qualified applicants will receive consideration for employment without regard to race religion color age sex national origin sexual orientation gender identity disability status or protected veteran statusvisa sponsorship may be available for this position'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejMqC3iJrDOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to sqlite3\n",
        "conn = sqlite3.connect('techsearch.sqlite3')\n",
        "curs = conn.cursor()\n",
        "curs.execute('drop table if exists listings')\n",
        "indeed_df.to_sql('listings', con=conn)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}